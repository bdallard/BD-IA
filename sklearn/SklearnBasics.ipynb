{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"http://www.dallard.tech/file/logo1.png\" style=\"float:left; max-width: 120px; display: inline\" alt=\"Dallard Consulting\"/> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage Statistique / Machine avec <a href=\"https://www.python.org/\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Python_logo_and_wordmark.svg/390px-Python_logo_and_wordmark.svg.png\" style=\"max-width: 150px; display: inline\" alt=\"Python\"/></a> & <a href=\"http://scikit-learn.org/stable/#\"><img src=\"http://scikit-learn.org/stable/_static/scikit-learn-logo-small.png\" style=\"max-width: 180px; display: inline\" alt=\"Scikit-Learn\"/></a>\n",
    "**Petit résumé**: Ce notebook introduit l'utilisation de la librairie `scikit-learn` pour la modélisation et l'apprentissage. Pourquoi utiliser `scikit-learn` ? Ou non ? Liste des fonctionnalités, quelques exemples de mise en oeuvre de modélisation régression logistique, $k$-plus proches voisins, arbres de décision, forêts aléatoires.On vera aussi l'optimisation des paramètres (complexité) des modèles par validation croisée, les fontions de chaînage (*pipeline*) de transformations et estimations. D'autres fonctionalités de `Scikit-learn` sont abordées dans les prochains cours. \n",
    "\n",
    "\n",
    "**Avertissement :** Ce notebook est plutôt technique, pas de problème si vous ne comprenez pas tout directement dès la première lecture prenez le temps de le lire 'oklm' !  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction\n",
    "### 1.1 Scikit-learn basic \n",
    "L'objectif de ce notebook est d'introduire l'utilisation de la librairie `scikit-learn` de Python. Seule l'utilisation directe des fonctions de modélisation sont abordées. Petit rappel générique de `scikit-learn`. \n",
    "\n",
    "- Cette librairie manipule des objets de classe `array` de `numpy` *chargés en mémoire* et donc de taille limitée par la RAM de l'ordinateur; de façon analogue R charge en RAM des objets de type `data.frame`.\n",
    "- `Scikit-learn` reconnaît quelque fois la classe `DataFrame` de `pandas`. Une variable binaire est simplement remplacée par un codage *(0,1)* mais, en présence de plusieurs modalités, traiter celles-ci comme des entiers n'a pas de sens statistique et remplacer une variable qualitative par l'ensemble des indicatrices (*dummy variables (0,1)*) de ses modalités  complique les stratégies de sélection de modèle tout en rendant inexploitable l'interprétation statistique. \n",
    "- Les implémentations en Python de certains algorithmes dans `scikit-learn` sont souvent rapide et utilisent implicitement les capacités de parallélisation.\n",
    "\n",
    "\n",
    "### 1.2 Fonctions d'apprentissage de Scikit-learn\n",
    "La communauté qui développe cette librairie est très active et la fait évoluer très rapidement.  Ne pas hésiter à consulter la [documentation](http://scikit-learn.org/stable/user_guide.html) pour des compléments. Voici une sélection de ses principales fonctionnalités en lien avec la modélisation : \n",
    "\n",
    "- Transformations (standardisation, discrétisation binaire, regroupement de modalités, imputations rudimentaires de données manquantes) , \"vectorisation\" de corpus de textes (encodage, catalogue, Tf-idf), images;\n",
    "- Modéle linéaire général avec pénalisation (ridge, lasso, elastic net...), analyse discriminante linéaire et quadratique,  $k$ plus proches voisins,  processus gaussiens, classifieur bayésien naïf, arbres de régression et classification (CART), agrégation de modèles (bagging, random forest, adaboost, gradient tree boosting), perceptron multicouche (réseau de neurones), SVM (classification, régression, détection d'atypiques...);\n",
    "- Algorithmes de validation croisée (loo, k-fold, VC stratifiée...) et sélection de modèles, optimisation sur une grille de paramètres, séparation aléatoire apprentissage et test, courbe ROC;\n",
    "- Enchaînement (*pipeline*) de traitements.\n",
    "\n",
    "En résumé, cette librairie est focalisée sur les aspects \"machine\" de l'apprentissage de données quantitatives (séries, signaux, images) volumineuses. \n",
    "\n",
    "### 1.3 Objectif \n",
    "Illustrer la mise en oeuvre de quelques fonctionnalités ainsi que apprendre à consulter la [documentation](http://scikit-learn.org/stable/user_guide.html) et ses nombreux [exemples](http://scikit-learn.org/stable/auto_examples/index.html) pour plus de détails sur les possibilités d'utilisation de `scikit-learn`. \n",
    "\n",
    "Deux jeux de données élémentaires sont utilisés, des variables explicatives qualitatives et quantitatives généralement dans un objet de la classe `DataFrame`. Pour être utilisé dans `scikit-learn` les données doivent souvent être transformées en un objet de classe `Array` de `numpy` par le  remplacement des variables qualitatives par les indicatrices de leurs modalités.  On peut aussi noterun autre ensemble de données, lui entièrement quantitatif. C'est un problème classique et simplifié de [reconnaissance de caractères](http://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits) qui est inclus dans la librairie `scikit-learn`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Extraction des échantillons\n",
    "Le travail préliminaire consiste à séparer les échantillons en une partie *apprentissage* et une autre de *test* pour estimer sans biais l'[erreur de prévision](http://wikistat.fr/pdf/st-m-app-risque-estim.pdf). L'optimisation (biais-variance) de la complexité des modèles est réalisée en minimisant l'erreur estimée par [validation croisée](http://wikistat.fr/pdf/st-m-app-risque-estim.pdf) $V-fold$. \n",
    "\n",
    "### 2.1 Données \"Caractères\"\n",
    "Elles sont disponibles dans la librairie `Scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[  0.,   0.,   5., ...,   0.,   0.,   0.],\n",
      "       [  0.,   0.,   0., ...,  10.,   0.,   0.],\n",
      "       [  0.,   0.,   0., ...,  16.,   9.,   0.],\n",
      "       ..., \n",
      "       [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
      "       [  0.,   0.,   2., ...,  12.,   0.,   0.],\n",
      "       [  0.,   0.,  10., ...,  12.,   1.,   0.]]), 'target': array([0, 1, 2, ..., 8, 9, 8]), 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'images': array([[[  0.,   0.,   5., ...,   1.,   0.,   0.],\n",
      "        [  0.,   0.,  13., ...,  15.,   5.,   0.],\n",
      "        [  0.,   3.,  15., ...,  11.,   8.,   0.],\n",
      "        ..., \n",
      "        [  0.,   4.,  11., ...,  12.,   7.,   0.],\n",
      "        [  0.,   2.,  14., ...,  12.,   0.,   0.],\n",
      "        [  0.,   0.,   6., ...,   0.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,   0., ...,   5.,   0.,   0.],\n",
      "        [  0.,   0.,   0., ...,   9.,   0.,   0.],\n",
      "        [  0.,   0.,   3., ...,   6.,   0.,   0.],\n",
      "        ..., \n",
      "        [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
      "        [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
      "        [  0.,   0.,   0., ...,  10.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,   0., ...,  12.,   0.,   0.],\n",
      "        [  0.,   0.,   3., ...,  14.,   0.,   0.],\n",
      "        [  0.,   0.,   8., ...,  16.,   0.,   0.],\n",
      "        ..., \n",
      "        [  0.,   9.,  16., ...,   0.,   0.,   0.],\n",
      "        [  0.,   3.,  13., ...,  11.,   5.,   0.],\n",
      "        [  0.,   0.,   0., ...,  16.,   9.,   0.]],\n",
      "\n",
      "       ..., \n",
      "       [[  0.,   0.,   1., ...,   1.,   0.,   0.],\n",
      "        [  0.,   0.,  13., ...,   2.,   1.,   0.],\n",
      "        [  0.,   0.,  16., ...,  16.,   5.,   0.],\n",
      "        ..., \n",
      "        [  0.,   0.,  16., ...,  15.,   0.,   0.],\n",
      "        [  0.,   0.,  15., ...,  16.,   0.,   0.],\n",
      "        [  0.,   0.,   2., ...,   6.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,   2., ...,   0.,   0.,   0.],\n",
      "        [  0.,   0.,  14., ...,  15.,   1.,   0.],\n",
      "        [  0.,   4.,  16., ...,  16.,   7.,   0.],\n",
      "        ..., \n",
      "        [  0.,   0.,   0., ...,  16.,   2.,   0.],\n",
      "        [  0.,   0.,   4., ...,  16.,   2.,   0.],\n",
      "        [  0.,   0.,   5., ...,  12.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,  10., ...,   1.,   0.,   0.],\n",
      "        [  0.,   2.,  16., ...,   1.,   0.,   0.],\n",
      "        [  0.,   0.,  15., ...,  15.,   0.,   0.],\n",
      "        ..., \n",
      "        [  0.,   4.,  16., ...,  16.,   6.,   0.],\n",
      "        [  0.,   8.,  16., ...,  16.,   8.,   0.],\n",
      "        [  0.,   1.,   8., ...,  12.,   1.,   0.]]]), 'DESCR': \"Optical Recognition of Handwritten Digits Data Set\\n===================================================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttp://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\nReferences\\n----------\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}\n"
     ]
    }
   ],
   "source": [
    "# Importations \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "%matplotlib inline\n",
    "# les données\n",
    "digits = datasets.load_digits()\n",
    "# Contenu et mode d'obtention\n",
    "print(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109630f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_and_labels = list(zip(digits.images, \n",
    "   digits.target))\n",
    "for index, (image, label) in  enumerate(images_and_labels[:8]):\n",
    "     plt.subplot(2, 4, index + 1)\n",
    "     plt.axis('off')\n",
    "     plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "     plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables prédictives et cible\n",
    "X=digits.data\n",
    "y=digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Données \"Titanic\"\n",
    "\n",
    "Les données sur le naufrage du Titanic sont décrites dans le calepin consacré à la librairie *pandas*. Reconstruire la table des données en lisant le fichier .csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surv</th>\n",
       "      <th>Classe</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Age</th>\n",
       "      <th>Prix</th>\n",
       "      <th>Port</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Surv Classe   Genre   Age     Prix Port\n",
       "0    0      3    male  22.0   7.2500    S\n",
       "1    1      1  female  38.0  71.2833    C\n",
       "2    1      3  female  26.0   7.9250    S\n",
       "3    1      1  female  35.0  53.1000    S\n",
       "4    0      3    male  35.0   8.0500    S"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lire les données d'apprentissage\n",
    "import pandas as pd\n",
    "path=''  # si les données sont déjà dans le répertoire courant SINON metter le bon chemin \n",
    "# path='http://www.math.univ-toulouse.fr/~besse/Wikistat/data/'\n",
    "df=pd.read_csv(path+'titanic-train.csv',skiprows=1,header=None,usecols=[1,2,4,5,9,11],\n",
    "  names=[\"Surv\",\"Classe\",\"Genre\",\"Age\",\"Prix\",\"Port\"],dtype={\"Surv\":object,\"Classe\":object,\"Genre\":object,\"Port\":object})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Surv      category\n",
       "Classe    category\n",
       "Genre     category\n",
       "Age        float64\n",
       "Prix       float64\n",
       "Port      category\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # dimensions\n",
    "# Redéfinir les types \n",
    "df[\"Surv\"]=pd.Categorical(df[\"Surv\"],ordered=False)\n",
    "df[\"Classe\"]=pd.Categorical(df[\"Classe\"],ordered=False)\n",
    "df[\"Genre\"]=pd.Categorical(df[\"Genre\"],ordered=False)\n",
    "df[\"Port\"]=pd.Categorical(df[\"Port\"],ordered=False)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Surv      891\n",
       "Classe    891\n",
       "Genre     891\n",
       "Age       714\n",
       "Prix      891\n",
       "Port      889\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation des valeurs manquantes\n",
    "df[\"Age\"]=df[\"Age\"].fillna(df[\"Age\"].median())\n",
    "df.Port=df[\"Port\"].fillna(\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surv</th>\n",
       "      <th>Classe</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Age</th>\n",
       "      <th>Prix</th>\n",
       "      <th>Port</th>\n",
       "      <th>AgeQ</th>\n",
       "      <th>PrixQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vnon</td>\n",
       "      <td>Cl3</td>\n",
       "      <td>Gmas</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Ps</td>\n",
       "      <td>Ag1</td>\n",
       "      <td>Pr1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voui</td>\n",
       "      <td>Cl1</td>\n",
       "      <td>Gfem</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Pc</td>\n",
       "      <td>Ag3</td>\n",
       "      <td>Pr3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voui</td>\n",
       "      <td>Cl3</td>\n",
       "      <td>Gfem</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Ps</td>\n",
       "      <td>Ag2</td>\n",
       "      <td>Pr1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voui</td>\n",
       "      <td>Cl1</td>\n",
       "      <td>Gfem</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Ps</td>\n",
       "      <td>Ag3</td>\n",
       "      <td>Pr3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vnon</td>\n",
       "      <td>Cl3</td>\n",
       "      <td>Gmas</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Ps</td>\n",
       "      <td>Ag3</td>\n",
       "      <td>Pr1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Surv Classe Genre   Age     Prix Port AgeQ PrixQ\n",
       "0  Vnon    Cl3  Gmas  22.0   7.2500   Ps  Ag1   Pr1\n",
       "1  Voui    Cl1  Gfem  38.0  71.2833   Pc  Ag3   Pr3\n",
       "2  Voui    Cl3  Gfem  26.0   7.9250   Ps  Ag2   Pr1\n",
       "3  Voui    Cl1  Gfem  35.0  53.1000   Ps  Ag3   Pr3\n",
       "4  Vnon    Cl3  Gmas  35.0   8.0500   Ps  Ag3   Pr1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Discrétiser les variables quantitatives\n",
    "df[\"AgeQ\"]=pd.qcut(df.Age,3,labels=[\"Ag1\",\"Ag2\",\"Ag3\"])\n",
    "df[\"PrixQ\"]=pd.qcut(df.Prix,3,labels=[\"Pr1\",\"Pr2\",\"Pr3\"])\n",
    "# redéfinir les noms des modalités \n",
    "df[\"Surv\"]=df[\"Surv\"].cat.rename_categories([\"Vnon\",\"Voui\"])\n",
    "df[\"Classe\"]=df[\"Classe\"].cat.rename_categories([\"Cl1\",\"Cl2\",\"Cl3\"])\n",
    "df[\"Genre\"]=df[\"Genre\"].cat.rename_categories([\"Gfem\",\"Gmas\"])\n",
    "df[\"Port\"]=df[\"Port\"].cat.rename_categories([\"Pc\",\"Pq\",\"Ps\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Surv      891\n",
       "Classe    891\n",
       "Genre     891\n",
       "Age       891\n",
       "Prix      891\n",
       "Port      891\n",
       "AgeQ      891\n",
       "PrixQ     891\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#petite vérification \n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Construction des échantillons d'entrainement et de test \n",
    "\n",
    "Le jeu de données (dit dataset) dont vous disposez constitue une **ressource précieuse**, il faut pouvoir l’utiliser à bon escient afin de pouvoir à la fois choisir un modèle et l'entraîner, mais aussi de pouvoir tester la qualité de ce modèle.\n",
    "\n",
    "**La première question à se poser est : est-ce qu’on va utiliser toutes les données d'exemple dont on dispose ?**\n",
    "\n",
    "En effet, s'il s’avère qu’on a beaucoup de données d’entraînement et/ou que l’algorithme d’apprentissage est lourd, il est possible qu’utiliser toutes les données prennent énormément de temps et/ou de ressources hardware. Dans ce cas, il faut naturellement échantillonner et ne récupérer qu’un petit pourcentage du dataset qui servira au travail de modélisation pour aller plus vite.\n",
    "Pour minimiser ce problème, la meilleure approche est de séparer dès le départ notre jeu de données en deux parties distinctes :\n",
    "- Le **training set**, qui va nous permettre d’entraîner notre modèle, et sera utilisé par l’algorithme d’apprentissage. \n",
    "- **Le testing set**, qui permet de mesurer l’erreur du modèle final sur des données qu’il n’a jamais vues. On va simplement passer ces données comme s'il s'agissait de données que l’on n'a encore jamais rencontrées (comme cela va se passer ensuite en pratique pour prédire de nouvelles données) et mesurer la performance de notre modèle sur ces données. \n",
    "\n",
    "C'est donc dans cette optique que l'on va construire des indicatrices de variables descriptive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surv_Vnon</th>\n",
       "      <th>Surv_Voui</th>\n",
       "      <th>Classe_Cl1</th>\n",
       "      <th>Classe_Cl2</th>\n",
       "      <th>Classe_Cl3</th>\n",
       "      <th>Genre_Gfem</th>\n",
       "      <th>Genre_Gmas</th>\n",
       "      <th>Port_Pc</th>\n",
       "      <th>Port_Pq</th>\n",
       "      <th>Port_Ps</th>\n",
       "      <th>AgeQ_Ag1</th>\n",
       "      <th>AgeQ_Ag2</th>\n",
       "      <th>AgeQ_Ag3</th>\n",
       "      <th>PrixQ_Pr1</th>\n",
       "      <th>PrixQ_Pr2</th>\n",
       "      <th>PrixQ_Pr3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Surv_Vnon  Surv_Voui  Classe_Cl1  Classe_Cl2  Classe_Cl3  Genre_Gfem  \\\n",
       "0          1          0           0           0           1           0   \n",
       "1          0          1           1           0           0           1   \n",
       "2          0          1           0           0           1           1   \n",
       "3          0          1           1           0           0           1   \n",
       "4          1          0           0           0           1           0   \n",
       "\n",
       "   Genre_Gmas  Port_Pc  Port_Pq  Port_Ps  AgeQ_Ag1  AgeQ_Ag2  AgeQ_Ag3  \\\n",
       "0           1        0        0        1         1         0         0   \n",
       "1           0        1        0        0         0         0         1   \n",
       "2           0        0        0        1         0         1         0   \n",
       "3           0        0        0        1         0         0         1   \n",
       "4           1        0        0        1         0         0         1   \n",
       "\n",
       "   PrixQ_Pr1  PrixQ_Pr2  PrixQ_Pr3  \n",
       "0          1          0          0  \n",
       "1          0          0          1  \n",
       "2          1          0          0  \n",
       "3          0          0          1  \n",
       "4          1          0          0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construction des indicatrices\n",
    "df_q=df.drop([\"Age\",\"Prix\"],axis=1)\n",
    "df_q.head()\n",
    "# Indicatrices\n",
    "dc=pd.DataFrame(pd.get_dummies(df_q[[\"Surv\",\"Classe\",\"Genre\",\"Port\",\"AgeQ\",\"PrixQ\"]]))\n",
    "dc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Surv_Voui', 'Classe_Cl1', 'Classe_Cl2', 'Classe_Cl3', 'Genre_Gfem',\n",
       "       'Port_Pc', 'Port_Pq', 'Port_Ps', 'AgeQ_Ag1', 'AgeQ_Ag2', 'AgeQ_Ag3',\n",
       "       'PrixQ_Pr1', 'PrixQ_Pr2', 'PrixQ_Pr3', 'Age', 'Prix'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table des indicatrices\n",
    "df1=pd.get_dummies(df_q[[\"Surv\",\"Classe\",\"Genre\",\"Port\",\"AgeQ\",\"PrixQ\"]])\n",
    "# Une seule indicatrice par variable binaire\n",
    "df1=df1.drop([\"Surv_Vnon\",\"Genre_Gmas\"],axis=1)\n",
    "# Variables quantitatives\n",
    "df2=df[[\"Age\",\"Prix\"]]\n",
    "# Concaténation\n",
    "df_c=pd.concat([df1,df2],axis=1)\n",
    "# Vérification\n",
    "df_c.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des échantillons d'apprentissage et test\n",
    "# variables explicatives\n",
    "T=df_c.drop([\"Surv_Voui\"],axis=1)\n",
    "# Variable à modéliser\n",
    "z=df_c[\"Surv_Voui\"]\n",
    "# Extractions\n",
    "from sklearn.model_selection import train_test_split\n",
    "T_train,T_test,z_train,z_test=train_test_split(T,z,test_size=0.2,random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention**: l'échantillon test des données \"Titanic\" est relativement petit, l'estimation de l'erreur de prévision est donc sujette à caution car probablement de grande variance. Il suffit de changer l'initialisation (paramètre ` random_state`) et ré-exécuter les scripts pour s'en assurer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
